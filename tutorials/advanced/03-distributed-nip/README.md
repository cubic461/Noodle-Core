# ðŸŒ Distributed NIP Systems

> **NIP v3.0.0 - Advanced Tutorial Series**
> 
> Building scalable, fault-tolerant NIP systems for production environments

## Table of Contents

1. [Introduction](#introduction)
2. [Distributed Architecture Patterns](#distributed-architecture-patterns)
3. [Message Queues](#message-queues)
4. [Service Discovery](#service-discovery)
5. [Load Balancing](#load-balancing)
6. [Fault Tolerance & Retry Logic](#fault-tolerance--retry-logic)
7. [Distributed Transactions](#distributed-transactions)
8. [Horizontal Scaling Strategies](#horizontal-scaling-strategies)
9. [Production Best Practices](#production-best-practices)
10. [Practical Exercises](#practical-exercises)

---

## Introduction

As NIP systems grow in complexity and user base, moving from single-instance to distributed architectures becomes essential. This tutorial covers the advanced patterns and practices needed to build production-grade distributed NIP systems that can scale horizontally while maintaining reliability and consistency.

### Learning Objectives

By the end of this tutorial, you will be able to:
- Design distributed NIP architectures using proven patterns
- Implement message queues for asynchronous communication
- Set up service discovery for dynamic environments
- Configure load balancing strategies
- Build fault-tolerant systems with retry logic
- Handle distributed transactions correctly
- Scale NIP systems horizontally

### Prerequisites

- Completion of Tutorial 02 (Production NIP Systems)
- Understanding of Docker and containerization
- Basic knowledge of networking concepts
- Familiarity with REST APIs and microservices

---

## Distributed Architecture Patterns

### 1. Event-Driven Architecture

In event-driven NIP systems, components communicate through events, enabling loose coupling and better scalability.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NIP       â”‚         â”‚   Message    â”‚         â”‚   Worker    â”‚
â”‚   Gateway   â”œâ”€â”€â”€â”€â”€â”€â”€â”€>â”‚    Queue     â”œâ”€â”€â”€â”€â”€â”€â”€â”€>â”‚   Pool      â”‚
â”‚             â”‚         â”‚              â”‚         â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                        â”‚                        â”‚
       v                        v                        v
  Events                 Event Broker              Event Handlers
```

**Implementation Example:**

```python
from dataclasses import dataclass
from typing import Any, Dict, Callable, Optional
from enum import Enum
import asyncio
import json
from datetime import datetime, timezone

class EventType(Enum):
    NIP_07_REQUEST = "nip_07_request"
    NIP_07_RESPONSE = "nip_07_response"
    NIP_42_AUTH = "nip_42_auth"
    NIP_46_BUNKER = "nip_46_bunker"
    PAYMENT_RECEIVED = "payment_received"
    PAYMENT_SETTLED = "payment_settled"

@dataclass
class Event:
    type: EventType
    payload: Dict[str, Any]
    timestamp: datetime
    correlation_id: str
    source: str
    reply_to: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "type": self.type.value,
            "payload": self.payload,
            "timestamp": self.timestamp.isoformat(),
            "correlation_id": self.correlation_id,
            "source": self.source,
            "reply_to": self.reply_to
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "Event":
        return cls(
            type=EventType(data["type"]),
            payload=data["payload"],
            timestamp=datetime.fromisoformat(data["timestamp"]),
            correlation_id=data["correlation_id"],
            source=data["source"],
            reply_to=data.get("reply_to")
        )

class EventBus:
    def __init__(self):
        self._subscribers: Dict[EventType, list[Callable]] = {}
        self._event_log: list[Event] = []
        self._locks: Dict[str, asyncio.Lock] = {}
    
    def subscribe(self, event_type: EventType, handler: Callable):
        """Subscribe to specific event types"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """Publish event to all subscribers"""
        self._event_log.append(event)
        
        if event.type in self._subscribers:
            tasks = [
                handler(event) 
                for handler in self._subscribers[event.type]
            ]
            await asyncio.gather(*tasks, return_exceptions=True)
    
    async def request_response(
        self, 
        event: Event, 
        timeout: float = 5.0
    ) -> Optional[Event]:
        """Publish event and wait for response"""
        response_queue = asyncio.Queue()
        
        async def response_handler(response: Event):
            if response.correlation_id == event.correlation_id:
                await response_queue.put(response)
        
        # Subscribe to responses
        response_type = EventType(
            event.type.value.replace("_request", "_response")
        )
        self.subscribe(response_type, response_handler)
        
        # Publish request
        await self.publish(event)
        
        # Wait for response
        try:
            response = await asyncio.wait_for(
                response_queue.get(), 
                timeout=timeout
            )
            return response
        except asyncio.TimeoutError:
            return None

# Usage example
async def setup_event_driven_nip():
    bus = EventBus()
    
    # Event handler for NIP-07 requests
    async def handle_nip07_request(event: Event):
        # Process request asynchronously
        response = Event(
            type=EventType.NIP_07_RESPONSE,
            payload={"result": "signed"},
            timestamp=datetime.now(timezone.utc),
            correlation_id=event.correlation_id,
            source="nip07_worker",
            reply_to=event.source
        )
        await bus.publish(response)
    
    bus.subscribe(EventType.NIP_07_REQUEST, handle_nip07_request)
    
    # Send request
    request = Event(
        type=EventType.NIP_07_REQUEST,
        payload={"data": "message to sign"},
        timestamp=datetime.now(timezone.utc),
        correlation_id="req-123",
        source="api_gateway"
    )
    
    response = await bus.request_response(request)
    return response
```

### 2. CQRS (Command Query Responsibility Segregation)

Separate read and write operations for optimal performance in distributed NIP systems.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     API Gateway                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                        â”‚
       v                        v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Write     â”‚         â”‚    Read     â”‚
â”‚   Side      â”‚         â”‚    Side     â”‚
â”‚             â”‚         â”‚             â”‚
â”‚ - Commands  â”‚         â”‚ - Queries   â”‚
â”‚ - Validate  â”‚         â”‚ - Optimize  â”‚
â”‚ - Store     â”‚         â”‚ - Cache     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                      â”‚
       v                      v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Primary    â”‚         â”‚  Read       â”‚
â”‚  Database   â”‚â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  Replicas   â”‚
â”‚             â”‚  Sync   â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation Example:**

```python
from abc import ABC, abstractmethod
from typing import List, Optional
import asyncio

class Command(ABC):
    """Base class for commands (write operations)"""
    pass

class Query(ABC):
    """Base class for queries (read operations)"""
    pass

class CommandHandler(ABC):
    @abstractmethod
    async def handle(self, command: Command) -> Any:
        pass

class QueryHandler(ABC):
    @abstractmethod
    async def handle(self, query: Query) -> Any:
        pass

# Commands
class CreateInvoiceCommand(Command):
    def __init__(self, amount: int, metadata: Dict[str, Any]):
        self.amount = amount
        self.metadata = metadata

class ProcessPaymentCommand(Command):
    def __init__(self, invoice_id: str, payment_hash: str):
        self.invoice_id = invoice_id
        self.payment_hash = payment_hash

# Queries
class GetInvoiceQuery(Query):
    def __init__(self, invoice_id: str):
        self.invoice_id = invoice_id

class ListInvoicesQuery(Query):
    def __init__(self, limit: int = 10, offset: int = 0):
        self.limit = limit
        self.offset = offset

# Command Handlers
class CreateInvoiceHandler(CommandHandler):
    def __init__(self, write_db, event_bus):
        self.write_db = write_db
        self.event_bus = event_bus
    
    async def handle(self, command: CreateInvoiceCommand) -> str:
        # Write to primary database
        invoice_id = await self.write_db.create_invoice(
            amount=command.amount,
            metadata=command.metadata
        )
        
        # Publish event
        event = Event(
            type=EventType.INVOICE_CREATED,
            payload={"invoice_id": invoice_id, "amount": command.amount},
            timestamp=datetime.now(timezone.utc),
            correlation_id=f"inv-{invoice_id}",
            source="write_service"
        )
        await self.event_bus.publish(event)
        
        return invoice_id

# Query Handlers (with caching)
class GetInvoiceHandler(QueryHandler):
    def __init__(self, read_db, cache):
        self.read_db = read_db
        self.cache = cache
    
    async def handle(self, query: GetInvoiceQuery) -> Optional[Dict]:
        # Try cache first
        cached = await self.cache.get(f"invoice:{query.invoice_id}")
        if cached:
            return cached
        
        # Fall back to read replica
        invoice = await self.read_db.get_invoice(query.invoice_id)
        if invoice:
            await self.cache.set(
                f"invoice:{query.invoice_id}", 
                invoice, 
                ttl=300
            )
        
        return invoice
```

### 3. Saga Pattern for Distributed Transactions

The Saga pattern manages distributed transactions by breaking them into local transactions with compensating actions.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Saga Orchestrator                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚              â”‚
       v              v              v              v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Create   â”‚   â”‚ Reserve  â”‚   â”‚ Process  â”‚   â”‚ Notify  â”‚
â”‚ Invoice  â”‚   â”‚ Balance  â”‚   â”‚ Payment  â”‚   â”‚ User     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚              â”‚
       v              v              v              v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Delete   â”‚   â”‚ Release  â”‚   â”‚ Refund   â”‚   â”‚ Revert   â”‚
â”‚ Invoice  â”‚   â”‚ Balance  â”‚   â”‚ Payment  â”‚   â”‚ Notify   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    Compensate    Compensate    Compensate    Compensate
```

**Implementation Example:**

```python
from typing import Callable, Optional
import uuid

class SagaStep:
    def __init__(
        self,
        name: str,
        action: Callable,
        compensate: Optional[Callable] = None
    ):
        self.name = name
        self.action = action
        self.compensate = compensate
        self.completed = False
        self.compensated = False

class Saga:
    def __init__(self, name: str):
        self.name = name
        self.saga_id = str(uuid.uuid4())
        self.steps: list[SagaStep] = []
        self.current_step = 0
        self.status = "pending"
        self.error: Optional[Exception] = None
    
    def add_step(
        self,
        action: Callable,
        compensate: Optional[Callable] = None,
        name: Optional[str] = None
    ) -> "Saga":
        step = SagaStep(
            name=name or f"step_{len(self.steps) + 1}",
            action=action,
            compensate=compensate
        )
        self.steps.append(step)
        return self
    
    async def execute(self) -> bool:
        """Execute all steps, compensating on failure"""
        self.status = "executing"
        
        for step in self.steps:
            try:
                result = await step.action()
                step.completed = True
                self.current_step += 1
            except Exception as e:
                self.error = e
                self.status = "compensating"
                
                # Compensate all completed steps in reverse
                await self._compensate()
                
                self.status = "failed"
                return False
        
        self.status = "completed"
        return True
    
    async def _compensate(self):
        """Compensate completed steps in reverse order"""
        for step in reversed(self.steps[:self.current_step]):
            if step.completed and step.compensate:
                try:
                    await step.compensate()
                    step.compensated = True
                except Exception as e:
                    # Log compensation failure but continue
                    print(f"Compensation failed for {step.name}: {e}")

# Usage: Payment processing saga
async def create_payment_saga(
    invoice_id: str,
    amount: int,
    user_id: str
) -> Saga:
    saga = Saga("payment_processing")
    
    # Step 1: Create invoice
    async def create_invoice():
        await invoice_db.create(invoice_id, amount, user_id)
        print(f"Invoice {invoice_id} created")
    
    async def delete_invoice():
        await invoice_db.delete(invoice_id)
        print(f"Invoice {invoice_id} deleted")
    
    saga.add_step(create_invoice, delete_invoice, "create_invoice")
    
    # Step 2: Reserve balance
    async def reserve_balance():
        await balance_db.reserve(user_id, amount)
        print(f"Balance {amount} reserved for user {user_id}")
    
    async def release_balance():
        await balance_db.release(user_id, amount)
        print(f"Balance {amount} released for user {user_id}")
    
    saga.add_step(reserve_balance, release_balance, "reserve_balance")
    
    # Step 3: Process payment
    async def process_payment():
        payment_hash = await payment_gateway.process(invoice_id, amount)
        print(f"Payment processed: {payment_hash}")
        return payment_hash
    
    async def refund_payment():
        await payment_gateway.refund(invoice_id)
        print(f"Payment refunded for invoice {invoice_id}")
    
    saga.add_step(process_payment, refund_payment, "process_payment")
    
    # Step 4: Update invoice status
    async def update_status():
        await invoice_db.update_status(invoice_id, "paid")
        print(f"Invoice {invoice_id} marked as paid")
    
    async def revert_status():
        await invoice_db.update_status(invoice_id, "cancelled")
        print(f"Invoice {invoice_id} marked as cancelled")
    
    saga.add_step(update_status, revert_status, "update_status")
    
    return saga
```

---

## Message Queues

### RabbitMQ Integration

RabbitMQ provides reliable message delivery with flexible routing patterns.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NIP         â”‚         â”‚       RabbitMQ           â”‚
â”‚  Services    â”‚         â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”‚
       â”‚                 â”‚  â”‚ Exchangeâ”‚->â”‚Queue â”‚  â”‚
       â”‚                 â””â”€â”€â”¤    â”€â”€â”€â”€â”€â”‚  â”‚  1   â”‚  â”‚
       â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â”‚
       â”‚                                            â”‚
       v                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚ Exchangeâ”‚->â”‚Queue â”‚     â”‚
â”‚  Worker      â”‚        â”‚    â”€â”€â”€â”€â”€â”‚  â”‚  2   â”‚     â”‚
â”‚  Processes   â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

**RabbitMQ Implementation:**

```python
import aio_pika
import asyncio
from typing import Callable, Optional
import json

class RabbitMQMessageQueue:
    def __init__(self, url: str = "amqp://guest:guest@localhost/"):
        self.url = url
        self.connection: Optional[aio_pika.RobustConnection] = None
        self.channel: Optional[aio_pika.RobustChannel] = None
        self.exchanges: dict[str, aio_pika.RobustExchange] = {}
        self.queues: dict[str, aio_pika.RobustQueue] = {}
    
    async def connect(self):
        """Establish connection to RabbitMQ"""
        self.connection = await aio_pika.connect_robust(self.url)
        self.channel = await self.connection.channel()
        
        # Set prefetch count for fair dispatch
        await self.channel.set_qos(prefetch_count=10)
    
    async def declare_exchange(
        self,
        name: str,
        exchange_type: str = "direct"
    ) -> aio_pika.RobustExchange:
        """Declare an exchange"""
        if name not in self.exchanges:
            self.exchanges[name] = await self.channel.declare_exchange(
                name,
                exchange_type,
                durable=True
            )
        return self.exchanges[name]
    
    async def declare_queue(
        self,
        name: str,
        durable: bool = True,
        ttl: Optional[int] = None
    ) -> aio_pika.RobustQueue:
        """Declare a queue"""
        if name not in self.queues:
            arguments = {}
            if ttl:
                arguments["x-message-ttl"] = ttl
            
            self.queues[name] = await self.channel.declare_queue(
                name,
                durable=durable,
                arguments=arguments
            )
        return self.queues[name]
    
    async def bind_queue(
        self,
        queue_name: str,
        exchange_name: str,
        routing_key: str = ""
    ):
        """Bind queue to exchange with routing key"""
        queue = self.queues[queue_name]
        exchange = self.exchanges[exchange_name]
        await queue.bind(exchange, routing_key)
    
    async def publish(
        self,
        exchange_name: str,
        routing_key: str,
        message: dict,
        correlation_id: Optional[str] = None,
        reply_to: Optional[str] = None
    ):
        """Publish message to exchange"""
        exchange = self.exchanges[exchange_name]
        
        await exchange.publish(
            aio_pika.Message(
                body=json.dumps(message).encode(),
                correlation_id=correlation_id,
                reply_to=reply_to,
                delivery_mode=aio_pika.DeliveryMode.PERSISTENT
            ),
            routing_key=routing_key
        )
    
    async def consume(
        self,
        queue_name: str,
        handler: Callable,
        auto_ack: bool = False
    ):
        """Consume messages from queue"""
        queue = self.queues[queue_name]
        
        async with queue.iterator() as queue_iter:
            async for message in queue_iter:
                try:
                    data = json.loads(message.body.decode())
                    await handler(data, message)
                    if not auto_ack:
                        await message.ack()
                except Exception as e:
                    print(f"Error processing message: {e}")
                    if not auto_ack:
                        await message.nack(requeue=True)
    
    async def close(self):
        """Close connection"""
        if self.connection:
            await self.connection.close()

# Usage example
async def setup_nip_messaging():
    mq = RabbitMQMessageQueue()
    await mq.connect()
    
    # Declare exchanges
    await mq.declare_exchange("nip.requests", "topic")
    await mq.declare_exchange("nip.events", "fanout")
    await mq.declare_exchange("nip.responses", "direct")
    
    # Declare queues
    await mq.declare_queue("nip07.sign.requests", ttl=60000)
    await mq.declare_queue("nip07.sign.responses", ttl=60000)
    await mq.declare_queue("nip46.bunker.requests", ttl=60000)
    await mq.declare_queue("nip46.bunker.responses", ttl=60000)
    await mq.declare_queue("payments.events", durable=True)
    
    # Bind queues
    await mq.bind_queue("nip07.sign.requests", "nip.requests", "nip07.sign")
    await mq.bind_queue("nip46.bunker.requests", "nip.requests", "nip46.bunker")
    await mq.bind_queue("payments.events", "nip.events", "")
    
    return mq

# Message handler
async def handle_nip07_request(data: dict, message: aio_pika.IncomingMessage):
    print(f"Processing NIP-07 request: {data}")
    
    # Process request
    result = {
        "signature": "derived_signature_here",
        "pubkey": "user_pubkey"
    }
    
    # Send response
    mq = await setup_nip_messaging()
    await mq.publish(
        "nip.responses",
        message.reply_to,
        result,
        correlation_id=message.correlation_id
    )
```

### Apache Kafka Integration

Kafka provides high-throughput, scalable event streaming for NIP systems.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Kafka Cluster                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Broker 1â”‚  â”‚ Broker 2â”‚  â”‚ Broker 3â”‚  â”‚ Broker 4â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²              â–²              â–²              â–²
       â”‚              â”‚              â”‚              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Producer â”‚  â”‚ Producer â”‚  â”‚ Producer â”‚  â”‚ Producer â”‚
â”‚ NIP-07   â”‚  â”‚ NIP-42   â”‚  â”‚ NIP-46   â”‚  â”‚ Payments â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

       â–¼              â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Consumer â”‚  â”‚ Consumer â”‚  â”‚ Consumer â”‚  â”‚ Consumer â”‚
â”‚ Group 1  â”‚  â”‚ Group 2  â”‚  â”‚ Group 3  â”‚  â”‚ Group 4  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Kafka Implementation:**

```python
from aiokafka import AIOKafkaProducer, AIOKafkaConsumer
from aiokafka.structs import TopicPartition
import asyncio
import json
from typing import List, Optional

class KafkaMessageBroker:
    def __init__(
        self,
        bootstrap_servers: str = "localhost:9092",
        client_id: str = "nip-service"
    ):
        self.bootstrap_servers = bootstrap_servers
        self.client_id = client_id
        self.producer: Optional[AIOKafkaProducer] = None
        self.consumers: dict[str, AIOKafkaConsumer] = {}
    
    async def create_producer(self):
        """Create Kafka producer"""
        self.producer = AIOKafkaProducer(
            bootstrap_servers=self.bootstrap_servers,
            client_id=self.client_id,
            value_serializer=lambda v: json.dumps(v).encode(),
            acks="all",  # Wait for all replicas
            retries=3,
            max_in_flight_requests_per_connection=1
        )
        await self.producer.start()
        return self.producer
    
    async def publish(
        self,
        topic: str,
        message: dict,
        key: Optional[str] = None
    ):
        """Publish message to topic"""
        if not self.producer:
            await self.create_producer()
        
        await self.producer.send_and_wait(
            topic,
            value=message,
            key=key.encode() if key else None
        )
    
    async def publish_batch(
        self,
        messages: List[tuple[str, dict, Optional[str]]]
    ):
        """Publish multiple messages efficiently"""
        if not self.producer:
            await self.create_producer()
        
        for topic, message, key in messages:
            await self.producer.send(
                topic,
                value=message,
                key=key.encode() if key else None
            )
        
        await self.producer.flush()
    
    def create_consumer(
        self,
        topics: List[str],
        group_id: str,
        auto_offset_reset: str = "earliest"
    ) -> AIOKafkaConsumer:
        """Create Kafka consumer"""
        consumer = AIOKafkaConsumer(
            *topics,
            bootstrap_servers=self.bootstrap_servers,
            group_id=group_id,
            auto_offset_reset=auto_offset_reset,
            enable_auto_commit=False,
            value_deserializer=lambda m: json.loads(m.decode())
        )
        return consumer
    
    async def consume(
        self,
        topics: List[str],
        group_id: str,
        handler: callable,
        max_poll_records: int = 100
    ):
        """Consume messages from topics"""
        consumer = self.create_consumer(topics, group_id)
        await consumer.start()
        
        try:
            async for msg in consumer:
                try:
                    await handler(msg.value, msg)
                    # Commit offset after successful processing
                    await consumer.commit()
                except Exception as e:
                    print(f"Error processing message: {e}")
                    # Don't commit on error, will retry
        finally:
            await consumer.stop()
    
    async def close(self):
        """Close producer connection"""
        if self.producer:
            await self.producer.stop()

# NIP Events Configuration
KAFKA_TOPICS = {
    "nip07.requests": {
        "partitions": 3,
        "replication_factor": 2,
        "retention_ms": 86400000  # 24 hours
    },
    "nip42.auth": {
        "partitions": 3,
        "replication_factor": 2,
        "retention_ms": 86400000
    },
    "nip46.bunker": {
        "partitions": 5,
        "replication_factor": 2,
        "retention_ms": 86400000
    },
    "payments.events": {
        "partitions": 10,
        "replication_factor": 3,
        "retention_ms": 604800000  # 7 days
    },
    "audit.log": {
        "partitions": 3,
        "replication_factor": 2,
        "retention_ms": 2592000000  # 30 days
    }
}

# Usage example
async def handle_payment_event(event: dict, msg):
    event_type = event.get("type")
    
    if event_type == "invoice.paid":
        await process_paid_invoice(event)
    elif event_type == "invoice.expired":
        await process_expired_invoice(event)
    elif event_type == "payment.failed":
        await process_failed_payment(event)

async def setup_kafka_consumer():
    broker = KafkaMessageBroker()
    
    await broker.consume(
        topics=["payments.events"],
        group_id="payment-processor",
        handler=handle_payment_event
    )
```

---

## Service Discovery

Service discovery enables dynamic service registration and lookup in distributed environments.

### Consul-Based Discovery

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Consul Cluster                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Service    â”‚  â”‚   Service    â”‚  â”‚   Service    â”‚ â”‚
â”‚  â”‚   Registry   â”‚  â”‚    Health    â”‚  â”‚      KV      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²              â–²              â–²
       â”‚              â”‚              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NIP-07   â”‚  â”‚ NIP-42   â”‚  â”‚ NIP-46   â”‚
â”‚ Service  â”‚  â”‚ Service  â”‚  â”‚ Service  â”‚
â”‚          â”‚  â”‚          â”‚  â”‚          â”‚
â”‚ Register â”‚  â”‚ Register â”‚  â”‚ Register â”‚
â”‚ Discover â”‚  â”‚ Discover â”‚  â”‚ Discover â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Consul Integration:**

```python
import consul
import asyncio
from typing import List, Optional, Dict, Any
import requests
from dataclasses import dataclass
import socket

@dataclass
class ServiceInstance:
    id: str
    name: str
    address: str
    port: int
    tags: List[str]
    meta: Dict[str, str]

class ConsulServiceDiscovery:
    def __init__(self, host: str = "localhost", port: int = 8500):
        self.consul = consul.Consul(host=host, port=port)
        self.service_id: Optional[str] = None
        self.check_id: Optional[str] = None
    
    async def register_service(
        self,
        name: str,
        port: int,
        tags: Optional[List[str]] = None,
        meta: Optional[Dict[str, str]] = None,
        check_interval: str = "10s",
        check_timeout: str = "5s"
    ) -> str:
        """Register service with Consul"""
        
        # Get local IP
        hostname = socket.gethostname()
        local_ip = socket.gethostbyname(hostname)
        
        # Generate unique service ID
        service_id = f"{name}-{local_ip}-{port}"
        
        # Register service
        self.consul.agent.service.register(
            name=name,
            service_id=service_id,
            address=local_ip,
            port=port,
            tags=tags or [],
            meta=meta or {},
            check=consul.Check.http(
                f"http://{local_ip}:{port}/health",
                interval=check_interval,
                timeout=check_timeout
            )
        )
        
        self.service_id = service_id
        print(f"Registered service: {service_id}")
        return service_id
    
    async def deregister_service(self):
        """Deregister service from Consul"""
        if self.service_id:
            self.consul.agent.service.deregister(self.service_id)
            print(f"Deregistered service: {self.service_id}")
    
    def discover_service(
        self,
        service_name: str,
        tag: Optional[str] = None,
        passing_only: bool = True
    ) -> List[ServiceInstance]:
        """Discover service instances"""
        
        _, services = self.consul.health.service(
            service_name,
            tag=tag,
            passing=passing_only
        )
        
        instances = []
        for service in services:
            instances.append(ServiceInstance(
                id=service["Service"]["ID"],
                name=service["Service"]["Service"],
                address=service["Service"]["Address"],
                port=service["Service"]["Port"],
                tags=service["Service"]["Tags"],
                meta=service["Service"]["Meta"]
            ))
        
        return instances
    
    def get_healthy_instance(
        self,
        service_name: str,
        tag: Optional[str] = None
    ) -> Optional[ServiceInstance]:
        """Get a single healthy instance using round-robin"""
        instances = self.discover_service(service_name, tag)
        
        if not instances:
            return None
        
        # Simple round-robin (in production, use client-side load balancing)
        # This is a basic example
        return instances[0]
    
    def watch_service(
        self,
        service_name: str,
        callback: callable,
        index: Optional[int] = None
    ):
        """Watch for changes in service instances"""
        while True:
            try:
                index, services = self.consul.health.service(
                    service_name,
                    index=index,
                    passing=True
                )
                
                instances = [
                    ServiceInstance(
                        id=s["Service"]["ID"],
                        name=s["Service"]["Service"],
                        address=s["Service"]["Address"],
                        port=s["Service"]["Port"],
                        tags=s["Service"]["Tags"],
                        meta=s["Service"]["Meta"]
                    )
                    for s in services[1]
                ]
                
                callback(instances)
                
            except Exception as e:
                print(f"Error watching service: {e}")
                asyncio.sleep(5)

# Circuit Breaker with Service Discovery
class CircuitBreaker:
    def __init__(
        self,
        service_name: str,
        discovery: ConsulServiceDiscovery,
        failure_threshold: int = 5,
        recovery_timeout: int = 60
    ):
        self.service_name = service_name
        self.discovery = discovery
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        
        self.failures: Dict[str, int] = {}
        self.last_failure: Dict[str, float] = {}
        self.state: Dict[str, str] = {}  # open, closed, half-open
    
    async def call(
        self,
        endpoint: str,
        method: str = "GET",
        **kwargs
    ) -> Optional[Any]:
        """Make service call with circuit breaker"""
        
        # Get healthy instance
        instance = self.discovery.get_healthy_instance(self.service_name)
        if not instance:
            raise Exception(f"No healthy instances of {self.service_name}")
        
        instance_id = f"{instance.address}:{instance.port}"
        
        # Check circuit state
        if self.state.get(instance_id) == "open":
            if time.time() - self.last_failure[instance_id] > self.recovery_timeout:
                self.state[instance_id] = "half-open"
            else:
                raise Exception(f"Circuit open for {instance_id}")
        
        # Make request
        try:
            url = f"http://{instance.address}:{instance.port}{endpoint}"
            response = requests.request(method, url, **kwargs)
            response.raise_for_status()
            
            # Success - reset failures
            self.failures[instance_id] = 0
            self.state[instance_id] = "closed"
            
            return response.json()
        
        except Exception as e:
            # Failure - increment counter
            self.failures[instance_id] = self.failures.get(instance_id, 0) + 1
            self.last_failure[instance_id] = time.time()
            
            # Check threshold
            if self.failures[instance_id] >= self.failure_threshold:
                self.state[instance_id] = "open"
                print(f"Circuit opened for {instance_id}")
            
            raise e
```

---

## Load Balancing

Load balancing distributes incoming traffic across multiple service instances.

### Load Balancing Strategies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Load Balancer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Round  â”‚  â”‚Least    â”‚  â”‚ IP Hash â”‚  â”‚ Weightedâ”‚   â”‚
â”‚  â”‚  Robin  â”‚  â”‚Conn     â”‚  â”‚         â”‚  â”‚         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚            â”‚            â”‚            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                          â”‚
        v                                          v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Instance Pool   â”‚                    â”‚  Instance Pool   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚Instance 1â”‚    â”‚                    â”‚  â”‚Instance 3â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚                    â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚Instance 2â”‚    â”‚                    â”‚  â”‚Instance 4â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚                    â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚Instance 3â”‚    â”‚                    â”‚  â”‚Instance 5â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation:**

```python
from typing import List, Optional
import random
import hashlib
from collections import deque
import time

class LoadBalancer:
    def __init__(self):
        self.backends: List[dict] = []
        self.current_index = 0
    
    def add_backend(self, backend: dict):
        """Add backend server"""
        backend["active_requests"] = 0
        backend["last_used"] = 0
        self.backends.append(backend)
    
    def remove_backend(self, backend_id: str):
        """Remove backend server"""
        self.backends = [
            b for b in self.backends 
            if b["id"] != backend_id
        ]
    
    def get_backends(self) -> List[dict]:
        """Get all backends"""
        return self.backends

class RoundRobinBalancer(LoadBalancer):
    def get_next_backend(self) -> Optional[dict]:
        """Get next backend using round-robin"""
        if not self.backends:
            return None
        
        backend = self.backends[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.backends)
        return backend

class LeastConnectionsBalancer(LoadBalancer):
    def get_next_backend(self) -> Optional[dict]:
        """Get backend with least active connections"""
        if not self.backends:
            return None
        
        return min(
            self.backends,
            key=lambda b: b["active_requests"]
        )

class IPHashBalancer(LoadBalancer):
    def get_next_backend(self, client_ip: str) -> Optional[dict]:
        """Get backend based on client IP hash"""
        if not self.backends:
            return None
        
        # Hash IP to index
        hash_value = int(hashlib.md5(client_ip.encode()).hexdigest(), 16)
        index = hash_value % len(self.backends)
        
        return self.backends[index]

class WeightedRoundRobinBalancer(LoadBalancer):
    def __init__(self):
        super().__init__()
        self.weighted_queue: deque = deque()
    
    def add_backend(self, backend: dict):
        """Add backend with weight"""
        backend["active_requests"] = 0
        backend["weight"] = backend.get("weight", 1)
        self.backends.append(backend)
        self._rebuild_weighted_queue()
    
    def _rebuild_weighted_queue(self):
        """Rebuild weighted queue"""
        self.weighted_queue = deque()
        for backend in self.backends:
            for _ in range(backend["weight"]):
                self.weighted_queue.append(backend)
    
    def get_next_backend(self) -> Optional[dict]:
        """Get next backend using weighted round-robin"""
        if not self.weighted_queue:
            return None
        
        backend = self.weighted_queue[0]
        self.weighted_queue.rotate(-1)
        return backend

# NIP Service Load Balancer
class NIPServiceBalancer:
    def __init__(
        self,
        service_name: str,
        strategy: str = "least_connections"
    ):
        self.service_name = service_name
        self.balancer = self._create_balancer(strategy)
        self.discovery = ConsulServiceDiscovery()
    
    def _create_balancer(self, strategy: str) -> LoadBalancer:
        """Create load balancer based on strategy"""
        if strategy == "round_robin":
            return RoundRobinBalancer()
        elif strategy == "least_connections":
            return LeastConnectionsBalancer()
        elif strategy == "ip_hash":
            return IPHashBalancer()
        elif strategy == "weighted":
            return WeightedRoundRobinBalancer()
        else:
            raise ValueError(f"Unknown strategy: {strategy}")
    
    async def initialize(self):
        """Initialize with service discovery"""
        instances = self.discovery.discover_service(self.service_name)
        for instance in instances:
            self.balancer.add_backend({
                "id": instance.id,
                "address": instance.address,
                "port": instance.port,
                "tags": instance.tags
            })
    
    async def route_request(
        self,
        endpoint: str,
        client_ip: Optional[str] = None,
        **kwargs
    ) -> Optional[dict]:
        """Route request to appropriate backend"""
        
        # Get backend
        if isinstance(self.balancer, IPHashBalancer) and client_ip:
            backend = self.balancer.get_next_backend(client_ip)
        else:
            backend = self.balancer.get_next_backend()
        
        if not backend:
            raise Exception("No available backends")
        
        # Increment active requests
        backend["active_requests"] += 1
        
        try:
            # Make request
            url = f"http://{backend['address']}:{backend['port']}{endpoint}"
            response = requests.get(url, **kwargs)
            return response.json()
        finally:
            # Decrement active requests
            backend["active_requests"] -= 1
            backend["last_used"] = time.time()
```

---

## Fault Tolerance & Retry Logic

### Retry Patterns

```python
from typing import Callable, Optional, Type
from functools import wraps
import asyncio
import time
import random

class RetryConfig:
    def __init__(
        self,
        max_attempts: int = 3,
        base_delay: float = 1.0,
        max_delay: float = 60.0,
        exponential_base: float = 2.0,
        jitter: bool = True
    ):
        self.max_attempts = max_attempts
        self.base_delay = base_delay
        self.max_delay = max_delay
        self.exponential_base = exponential_base
        self.jitter = jitter

def retry_with_backoff(
    config: RetryConfig,
    exceptions: tuple[Type[Exception], ...] = (Exception,)
):
    """Decorator for retry with exponential backoff"""
    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            last_exception = None
            
            for attempt in range(config.max_attempts):
                try:
                    return await func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    
                    if attempt == config.max_attempts - 1:
                        # Last attempt, raise
                        raise
                    
                    # Calculate delay
                    delay = min(
                        config.base_delay * (config.exponential_base ** attempt),
                        config.max_delay
                    )
                    
                    # Add jitter
                    if config.jitter:
                        delay = delay * (0.5 + random.random() * 0.5)
                    
                    print(
                        f"Attempt {attempt + 1} failed, retrying in "
                        f"{delay:.2f}s: {e}"
                    )
                    await asyncio.sleep(delay)
            
            raise last_exception
        
        return wrapper
    return decorator

# Usage
@retry_with_backoff(
    config=RetryConfig(
        max_attempts=5,
        base_delay=1.0,
        exponential_base=2.0,
        jitter=True
    ),
    exceptions=(ConnectionError, TimeoutError)
)
async def call_nip_service(url: str, data: dict):
    response = await asyncio.to_thread(
        requests.post,
        url,
        json=data,
        timeout=10
    )
    response.raise_for_status()
    return response.json()
```

### Circuit Breaker Pattern

```python
from enum import Enum
import time

class CircuitState(Enum):
    CLOSED = "closed"
    OPEN = "open"
    HALF_OPEN = "half_open"

class CircuitBreaker:
    def __init__(
        self,
        failure_threshold: int = 5,
        success_threshold: int = 2,
        timeout: int = 60
    ):
        self.failure_threshold = failure_threshold
        self.success_threshold = success_threshold
        self.timeout = timeout
        
        self.failures = 0
        self.successes = 0
        self.state = CircuitState.CLOSED
        self.next_attempt = 0
    
    def record_success(self):
        """Record successful call"""
        self.failures = 0
        
        if self.state == CircuitState.HALF_OPEN:
            self.successes += 1
            if self.successes >= self.success_threshold:
                self.state = CircuitState.CLOSED
                self.successes = 0
    
    def record_failure(self):
        """Record failed call"""
        self.failures += 1
        
        if self.failures >= self.failure_threshold:
            self.state = CircuitState.OPEN
            self.next_attempt = time.time() + self.timeout
    
    def can_attempt(self) -> bool:
        """Check if call can be attempted"""
        if self.state == CircuitState.CLOSED:
            return True
        
        if self.state == CircuitState.OPEN:
            if time.time() >= self.next_attempt:
                self.state = CircuitState.HALF_OPEN
                return True
            return False
        
        if self.state == CircuitState.HALF_OPEN:
            return True
        
        return False
    
    def __call__(self, func: Callable):
        """Decorator to use circuit breaker"""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            if not self.can_attempt():
                raise Exception("Circuit breaker is OPEN")
            
            try:
                result = await func(*args, **kwargs)
                self.record_success()
                return result
            except Exception as e:
                self.record_failure()
                raise e
        
        return wrapper

# Usage
nip_circuit_breaker = CircuitBreaker(
    failure_threshold=5,
    success_threshold=2,
    timeout=60
)

@nip_circuit_breaker
async def call_external_nip_service(url: str):
    """Call external NIP service with circuit breaker"""
    # Implementation
    pass
```

### Bulkhead Pattern

The bulkhead pattern isolates resources to prevent cascading failures.

```python
import asyncio
from typing import Callable

class Bulkhead:
    def __init__(self, max_concurrent: int, max_queue_size: int):
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.queue = asyncio.Queue(maxsize=max_queue_size)
    
    async def execute(self, func: Callable, *args, **kwargs):
        """Execute function with bulkhead isolation"""
        
        # Wait for queue slot
        await self.queue.put(None)
        
        try:
            # Wait for execution slot
            async with self.semaphore:
                return await func(*args, **kwargs)
        finally:
            # Release queue slot
            await self.queue.get()

# Usage
nip07_bulkhead = Bulkhead(max_concurrent=10, max_queue_size=100)

@nip07_bulkhead.execute
async def process_nip07_request(request: dict):
    """Process NIP-07 request with bulkhead"""
    # Implementation
    pass
```

---

## Distributed Transactions

### Two-Phase Commit (2PC)

```python
class TwoPhaseCommitCoordinator:
    def __init__(self, participants: List[str]):
        self.participants = participants
        self.transaction_log = []
    
    async def prepare(self, transaction_id: str, operations: List[dict]):
        """Phase 1: Prepare all participants"""
        
        # Log prepare
        self.transaction_log.append({
            "phase": "prepare",
            "transaction_id": transaction_id,
            "operations": operations
        })
        
        # Send prepare to all participants
        prepare_results = []
        for participant in self.participants:
            try:
                result = await self._send_prepare(
                    participant,
                    transaction_id,
                    operations
                )
                prepare_results.append((participant, result))
            except Exception as e:
                # Prepare failed - rollback all
                await self.rollback(transaction_id)
                raise Exception(f"Prepare failed: {e}")
        
        # Check if all prepared
        all_prepared = all(
            result.get("prepared", False) 
            for _, result in prepare_results
        )
        
        if not all_prepared:
            await self.rollback(transaction_id)
            raise Exception("Not all participants prepared")
        
        return True
    
    async def commit(self, transaction_id: str):
        """Phase 2: Commit transaction"""
        
        # Log commit
        self.transaction_log.append({
            "phase": "commit",
            "transaction_id": transaction_id
        })
        
        # Send commit to all participants
        commit_results = []
        for participant in self.participants:
            try:
                result = await self._send_commit(
                    participant,
                    transaction_id
                )
                commit_results.append((participant, result))
            except Exception as e:
                # Log error but continue (retry logic needed)
                print(f"Commit error for {participant}: {e}")
        
        return all(
            result.get("committed", False) 
            for _, result in commit_results
        )
    
    async def rollback(self, transaction_id: str):
        """Rollback transaction"""
        
        # Log rollback
        self.transaction_log.append({
            "phase": "rollback",
            "transaction_id": transaction_id
        })
        
        # Send rollback to all participants
        for participant in self.participants:
            try:
                await self._send_rollback(participant, transaction_id)
            except Exception as e:
                print(f"Rollback error for {participant}: {e}")
    
    async def _send_prepare(
        self,
        participant: str,
        transaction_id: str,
        operations: List[dict]
    ):
        """Send prepare to participant"""
        # Implementation depends on your communication protocol
        pass
    
    async def _send_commit(self, participant: str, transaction_id: str):
        """Send commit to participant"""
        pass
    
    async def _send_rollback(self, participant: str, transaction_id: str):
        """Send rollback to participant"""
        pass
```

---

## Horizontal Scaling Strategies

### Scaling NIP Services

```python
import docker
from typing import List

class NIPServiceScaler:
    def __init__(
        self,
        service_name: str,
        min_instances: int = 2,
        max_instances: int = 10,
        target_cpu: float = 70.0,
        target_memory: float = 80.0
    ):
        self.service_name = service_name
        self.min_instances = min_instances
        self.max_instances = max_instances
        self.target_cpu = target_cpu
        self.target_memory = target_memory
        
        self.docker_client = docker.from_env()
    
    def get_current_instances(self) -> int:
        """Get current number of service instances"""
        try:
            service = self.docker_client.services.get(self.service_name)
            return service.attrs["Spec"]["Mode"]["Replicated"]["Replicas"]
        except Exception as e:
            print(f"Error getting instances: {e}")
            return self.min_instances
    
    def get_metrics(self) -> dict:
        """Get service metrics"""
        # Implementation depends on monitoring system
        # Return average CPU and memory usage
        return {
            "cpu_percent": 65.0,
            "memory_percent": 75.0
        }
    
    def scale(self, count: int):
        """Scale service to specific count"""
        count = max(self.min_instances, min(count, self.max_instances))
        
        try:
            service = self.docker_client.services.get(self.service_name)
            service.update_replicas(count)
            print(f"Scaled {self.service_name} to {count} instances")
        except Exception as e:
            print(f"Error scaling service: {e}")
    
    def auto_scale(self):
        """Auto-scale based on metrics"""
        current_instances = self.get_current_instances()
        metrics = self.get_metrics()
        
        # Scale up if CPU or memory above target
        if (
            metrics["cpu_percent"] > self.target_cpu or
            metrics["memory_percent"] > self.target_memory
        ):
            if current_instances < self.max_instances:
                self.scale(current_instances + 1)
        
        # Scale down if below target
        elif (
            metrics["cpu_percent"] < self.target_cpu * 0.5 and
            metrics["memory_percent"] < self.target_memory * 0.5
        ):
            if current_instances > self.min_instances:
                self.scale(current_instances - 1)

# Kubernetes HPA (Horizontal Pod Autoscaler) configuration
HPA_YAML = """
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nip-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nip-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
      selectPolicy: Max
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
"""
```

---

## Production Best Practices

### 1. Observability

```python
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time

# Define metrics
nip_requests_total = Counter(
    'nip_requests_total',
    'Total NIP requests',
    ['method', 'status']
)

nip_request_duration = Histogram(
    'nip_request_duration_seconds',
    'NIP request duration',
    ['method']
)

nip_active_connections = Gauge(
    'nip_active_connections',
    'Active NIP connections'
)

# Middleware for metrics tracking
async def track_metrics(request, call_next):
    """Track request metrics"""
    start_time = time.time()
    
    # Increment active connections
    nip_active_connections.inc()
    
    try:
        response = await call_next(request)
        
        # Record metrics
        method = request.method
        status = str(response.status_code)
        duration = time.time() - start_time
        
        nip_requests_total.labels(method=method, status=status).inc()
        nip_request_duration.labels(method=method).observe(duration)
        
        return response
    finally:
        # Decrement active connections
        nip_active_connections.dec()

# Start metrics server
start_http_server(9090)
```

### 2. Health Checks

```python
from fastapi import FastAPI
from pydantic import BaseModel
import psutil

app = FastAPI()

class HealthResponse(BaseModel):
    status: str
    version: str
    uptime: float
    memory_usage: float
    cpu_usage: float
    dependencies: dict

@app.get("/health")
async def health_check():
    """Comprehensive health check"""
    
    # Check dependencies
    dependencies = {
        "database": await check_database(),
        "redis": await check_redis(),
        "rabbitmq": await check_rabbitmq(),
        "kafka": await check_kafka()
    }
    
    all_healthy = all(
        dep["status"] == "healthy" 
        for dep in dependencies.values()
    )
    
    return HealthResponse(
        status="healthy" if all_healthy else "unhealthy",
        version="3.0.0",
        uptime=time.time() - start_time,
        memory_usage=psutil.virtual_memory().percent,
        cpu_usage=psutil.cpu_percent(),
        dependencies=dependencies
    )

async def check_database() -> dict:
    """Check database connectivity"""
    try:
        # Ping database
        await database.execute("SELECT 1")
        return {"status": "healthy", "response_time": 0.01}
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}
```

### 3. Graceful Shutdown

```python
from contextlib import asynccontextmanager
import signal

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Handle application lifespan"""
    # Startup
    print("Starting NIP service...")
    await connect_to_dependencies()
    
    # Setup signal handlers
    loop = asyncio.get_event_loop()
    
    def signal_handler(signum, frame):
        print(f"Received signal {signum}, shutting down...")
        raise KeyboardInterrupt
    
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
    
    yield
    
    # Shutdown
    print("Shutting down NIP service...")
    await close_connections()
    await flush_caches()
    print("Shutdown complete")

app = FastAPI(lifespan=lifespan)
```

---

## Practical Exercises

### Exercise 1: Implement Event-Driven NIP System

**Task**: Create an event-driven NIP system using the event bus pattern.

**Requirements**:
1. Define events for NIP-07, NIP-42, and NIP-46 operations
2. Implement event handlers for each protocol
3. Create an event bus that manages subscriptions
4. Implement request-response pattern
5. Add event logging and replay capabilities

**Bonus**:
- Implement event versioning
- Add event filtering
- Create event replay mechanism

### Exercise 2: Build Resilient Service Communication

**Task**: Implement circuit breaker and retry logic for inter-service communication.

**Requirements**:
1. Create a circuit breaker decorator
2. Implement exponential backoff retry logic
3. Add fallback mechanisms
4. Monitor circuit state
5. Implement bulkhead pattern

**Bonus**:
- Add metrics for circuit breaker state
- Implement adaptive retry strategies
- Create circuit breaker dashboard

### Exercise 3: Design Distributed Transaction

**Task**: Implement a Saga pattern for payment processing.

**Requirements**:
1. Define transaction steps
2. Implement compensating actions
3. Add transaction logging
4. Handle partial failures
5. Implement transaction recovery

**Bonus**:
- Add transaction timeout handling
- Implement parallel transaction steps
- Create transaction monitoring dashboard

### Exercise 4: Auto-Scaling NIP Service

**Task**: Create auto-scaling logic for NIP services.

**Requirements**:
1. Implement metrics collection
2. Create scaling logic
3. Add cooldown periods
4. Scale based on multiple metrics
5. Implement predictive scaling

**Bonus**:
- Add scaling policies
- Implement custom metrics
- Create scaling dashboard

---

## Conclusion

Distributed NIP systems require careful consideration of architecture patterns, communication strategies, and resilience mechanisms. By implementing the patterns and practices covered in this tutorial, you can build NIP systems that:

- **Scale horizontally** to handle increased load
- **Maintain availability** during failures
- **Process transactions reliably** across services
- **Recover gracefully** from errors
- **Monitor and debug** effectively in production

### Key Takeaways

1. **Event-driven architecture** enables loose coupling and better scalability
2. **Message queues** provide reliable asynchronous communication
3. **Service discovery** is essential for dynamic environments
4. **Load balancing** distributes traffic efficiently
5. **Fault tolerance** patterns prevent cascading failures
6. **Distributed transactions** require careful coordination
7. **Horizontal scaling** enables handling increased load

### Next Steps

1. **Deploy to production**: Apply these patterns in a production environment
2. **Monitor and iterate**: Use metrics to optimize performance
3. **Implement observability**: Add comprehensive monitoring and logging
4. **Test failure scenarios**: Verify fault tolerance mechanisms
5. **Optimize scaling**: Fine-tune auto-scaling policies

### Additional Resources

- [Microservices Patterns](https://microservices.io/patterns/)
- [Building Microservices](https://www.oreilly.com/library/view/building-microservices/9781491950340/)
- [Release It!](https://www.oreilly.com/library/view/release-it/9781680508458/)
- [NIP Implementation Guide](https://github.com/nbd-wtf/nostr-tools)

---

**Tutorial Version**: 3.0.0  
**Last Updated**: 2025-01-17  
**Author**: NIP Development Team  
**License**: MIT
